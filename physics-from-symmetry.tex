% Preamble ==================================================================
\documentclass[11pt]{article}
\usepackage{geometry}
\geometry{verbose,tmargin=2.5cm,bottom= 1.5cm,lmargin=2.5cm,rmargin=2.5cm}
\usepackage{float}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{mathtools}

\usepackage{tensor}
\usepackage{cancel}
\usepackage{wasysym}

\usepackage{amsthm} % theorem

\numberwithin{equation}{section}

\usepackage{titlesec,dsfont}

%Format section heading style
\usepackage{sectsty}
\sectionfont{\sffamily\bfseries\large}
\subsectionfont{\sffamily\normalsize\slshape}
\subsubsectionfont{\sffamily\small\itshape}
\paragraphfont{\sffamily\small\textbf}


%Put period after section number
\makeatletter
\def\@seccntformat#1{\csname the#1\endcsname.\quad}
\makeatother

%Bibliography
\usepackage[round]{natbib}
\bibliographystyle{genetics}

%Format captions
\usepackage[ labelsep=period, justification=raggedright, margin=10pt,font={small},labelfont={small,normal,bf,sf}]{caption}

\setlength{\parskip}{0ex} %No space between paragraphs.

\renewcommand{\familydefault}{\sfdefault}

\newcommand\indep{\protect\mathpalette{\protect\independenT}{\perp}}
\newcommand{\nindep}{\not\!\perp\!\!\!\perp}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}

%PUT ME LAST--------------------------------------------------
\usepackage[colorlinks=true
,urlcolor=blue
,anchorcolor=blue
,citecolor=blue
,filecolor=blue
,linkcolor=black
,menucolor=blue
,linktocpage=true
,pdfproducer=medialab
,pdfa=true
]{hyperref}

\makeatother %Put this last of all

% Symbol definitions
\newcommand{\defeq}{\coloneqq}
\renewcommand{\d}[1]{\ensuremath{\operatorname{d}\!{#1}}}
\newcommand{\deriv}[2]{\frac{\ensuremath{\operatorname{d}\!{#1}}}{\ensuremath{\operatorname{d}\!{#2}}}}
\newcommand{\derivn}[3]{\frac{\ensuremath{\operatorname{d}^{#1}\!{#2}}}{\ensuremath{\operatorname{d}\!{#3}^{#1}}}}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\tr}{tr}

% Make theorems bold
\makeatletter
\def\th@plain{%
  \thm@notefont{}% same as heading font
  \itshape % body font
}
\def\th@definition{%
  \thm@notefont{}% same as heading font
  \normalfont % body font
}
\makeatother

% Theorem definitions
\newtheorem{thm}{Theorem}[section]
\newtheorem{defn}{Definition}[section]
\newtheorem{cor}{Corollary}[section]
\newtheorem{prop}{Property}[section]
\newtheorem{rle}{Rule}[section]
\newtheorem{lma}{Lemma}[section]

%Preamble end--------------------------------------------------


\begin{document}



\begin{flushleft}
\textbf{\Large Notes on Physics from Symmetry}
\end{flushleft}

\begin{flushleft}
Author: Juvid Aryaman

Last compiled: \today
\end{flushleft}

\noindent This document contains my personal notes on Jakob Schwichtenberg's Physics from Symmetry \citep{Schwichtenberg15}, with a sprinkling of notes from my undergraduate physics course in quantum field theory (and, to a lesser extent, general relativity).


\section{Special relativity}

\subsection{Definitions and postulates} \label{sec:postualtes-sr}

In special relativity, \textbf{inertial frames of reference} are coordinate systems moving with constant velocity relative to each other. Special relativity has two basic postulates:
\begin{enumerate}
\item \textbf{The principal of relativity}: The laws of physics are the same in all inertial frames of reference.
\item \textbf{The invariance of the speed of light}: The velocity of light has the same value $c$ in all inertial frames of reference.
\end{enumerate}

\begin{thm}[Invariant of special relativity]\label{thm:invariant-sr}
Consider two events $A$ and $B$ in an inertial observer $O$'s frame of reference. Let the time interval measured by $O$ between the two events be $(\Delta t)$, and the three spatial intervals be $(\Delta x)$, $(\Delta y)$, $(\Delta z)$. Then, the quantity
\begin{equation}
(\Delta s)^2 \defeq (\Delta c t)^2 - (\Delta x)^2 - (\Delta y)^2 - (\Delta y)^2
\end{equation}
is \textbf{invariant} between all frames of reference. I.e.
\begin{equation}
(\Delta s') = (\Delta s)
\end{equation}
for any inertial frame of reference $O'$.
\end{thm}
\noindent Theorem \ref{thm:invariant-sr} follows directly from the invariance of the speed of light (consider a pair of mirrors, for two observers with relative velocity).

\begin{defn}[Proper time] \label{defn:proper-time}
Proper time, $\tau$, is the time measured by an observer in the special frame of reference where the object in question is at rest. In this frame of reference,
\begin{equation}
(\Delta s)^2 = (c \Delta \tau)^2.
\end{equation}
In the infinitesimal limit
\begin{equation}
(\d s)^2 = (c \d \tau)^2.
\end{equation}
\end{defn}
Physically, Defn.~\ref{defn:proper-time} means that all observers agree on the time interval between events for an observer who travels with the object in question. However, different observers \textbf{do not} in general agree on the time interval between events generally: $(\Delta t) \neq (\Delta t')$ -- this is called \textbf{time dilation}. 

\subsection{$c$ is an upper speed limit}
All observers agree on the value of $(\d s)^2=(c \d \tau)^2$. Furthermore, we commonly assume that there exists a minimal proper time of $\tau = 0$ for two events if $\Delta s^2 = 0$. We can therefore write that when $\tau = 0$
\begin{equation}
c^2 = \frac{(\d x)^2 + (\d y)^2 + (\d z)^2}{(\d t)^2}
\end{equation}
between two events with an infinitesimal distance. We can equate the right-hand side with a squared velocity, and hence
\begin{equation}
\tau = 0 \implies c^2 = v^2\ 
\end{equation}
so
\begin{equation}
(\d s)^2 \geq 0 \implies c^2 \geq v^2
\end{equation}
for \textbf{any} pair of events (which are causally connected, although how this follows is not immediately clear to me right now). 

\subsection{Tensor notation and Minkowski spacetime}

\begin{defn}[Four-vector (contravariant)]
A position four-\textbf{vector} is defined as
\begin{equation}
x^\mu = \begin{pmatrix}ct\\x\\y\\z\end{pmatrix} \equiv \begin{pmatrix}x^0\\x^1\\x^2\\x^3\end{pmatrix}.
\end{equation}
\end{defn}
\begin{defn}[Minkowski metric]
The Minkowski metric is defined as 
\begin{equation}
\eta_{\mu \nu} = \diag(1,-1,-1,-1).
\end{equation}
$\eta$ is used to compute distances and lengths in Minkowski space.
\end{defn}
\noindent We define $\eta^{\mu \nu}$ through the relation
\begin{equation}
\eta^{\mu \nu} \eta_{\nu \sigma} = \tensor{\delta}{^\mu_\sigma}
\end{equation}
where we have appled the \textbf{Einstein summation convention}, where a repeated Greek index implies a summation from 0 to 3 (where the zeroth index is time), and a repeated Roman index is summed from 1 to 3. Hence, for a matrix multiplication between two 3$\times$3 matricies $A$ and $B$, $(AB)_{ij} = A_{ik}B_{kj}$, and $(A^T)_{ij}=A_{ji}$.


\begin{defn}[One-form (covariant vector)]
We define a one-form as 
\begin{equation}
x_\mu = \eta_{\mu \nu}x^\nu.
\end{equation}
\end{defn} 
\noindent Thus,
\begin{equation}
\d s^2 = \eta_{\mu \nu} \d x^\mu \d x^\nu.
\end{equation}
\begin{defn}[Scalar product]
A scalar product between four-vectors $x$ and $y$ is defined as
\begin{equation}
x \cdot y \defeq x^\mu y^\nu \eta_{\mu \nu} = x_\mu y_\nu \eta^{\mu \nu} = x^\mu y_\mu = x_\nu y^\nu
\end{equation}
due to the symmetry of the metric: $\eta_{\mu \nu} = \eta_{\nu \mu}$.
\end{defn}

\paragraph{Ordering (spacing) of indicies} In order to be able to freely raise/lower indicies (without repeatedly writing the metric tensor), we can impose an ordering upon indicies of tensor fields -- which we can represent typographically with spacing between tensor indicies. A metric $g_{ij}$ (or $g^{ij}$) has the effect of lowering (or raising) a repeated index. For example,
\begin{equation}
g_{iq} \tensor{T}{^{abcd}_{efgh}^{ijkl}_{mnop}}  = \tensor{T}{^{abcd}_{efghq}^{jkl}_{mnop}}.
\end{equation}
(Proof of this, I imagine, requires background in differential geometry?)

\subsection{Lorentz transformations}
From the invariant of SR (Theorem~\ref{thm:invariant-sr}), we have
\begin{equation}
\d s'^2 = \d x'_\mu \d x'_\nu \eta^{\mu \nu} = \d x_\mu \d x_\nu \eta^{\mu \nu}
\end{equation}
for all reference frames. We denote $\Lambda$ as a (1,1) tensor field, which transforms a four-vector from one reference frame to another:
\begin{equation}
\d x'^\mu = \Lambda^\mu{}_{\nu} \d x ^\nu
\end{equation}
which leaves the $\d s^2$ invariant, i.e. $\d s'^2 = ds^2$. It follows that 
\begin{align}
\eta_{\mu \nu} &= \tensor{\Lambda}{^\sigma_\mu} \tensor{\Lambda}{^\delta_\nu} \eta_{\sigma \delta} \label{eq:lorentz-tfm-characteristic}\\
\eta &= \Lambda^T \eta \Lambda. \nonumber
\end{align}
The physical meaning of Eq.\eqref{eq:lorentz-tfm-characteristic} is that Lorentz transformations leave the scalar product of Minkowski spacetime invariant: i.e. changes between frames of reference that respect the two postualtes of special relativity (Section~\ref{sec:postualtes-sr}). Conservation of the scalar product is analogous to rigid rotation ($O$) in Euclidean space ($a \cdot b = a' \cdot b' = a^T O^T O b \implies O^T I O = I$), which preserves orientation ($\det(\Lambda)=1$).


Note that $\tensor{\Lambda}{^\mu_\nu} \neq \tensor{\Lambda}{_\nu^\mu}$. Beginning with Eq.\eqref{eq:lorentz-tfm-characteristic},
\begin{align*}
\tensor{\Lambda}{^\mu_\rho} \tensor{\Lambda}{^\nu_\sigma} \eta_{\mu \nu} &= \eta_{\rho \sigma}
\end{align*}
we can raise one index, and lower one index, of $\tensor{\Lambda}{^\nu_\sigma}$
\begin{align}
\tensor{\Lambda}{^\mu_\rho} \eta_{\mu \nu} \tensor{\Lambda}{^\nu_\sigma} \eta_{\nu \mu} \eta^{\sigma \lambda}  &= \eta_{\rho \sigma} \eta_{\nu \mu} \eta^{\sigma \lambda} \nonumber \\
\tensor{\Lambda}{^\mu_\rho} \tensor{\Lambda}{_\mu^\lambda} \cancel{\eta_{\mu \nu}} &=  \cancel{\eta_{\mu \nu}} \tensor{\delta}{_\rho^\lambda} \nonumber \\
\tensor{\Lambda}{^\mu_\rho} \tensor{\Lambda}{_\mu^\lambda} &= \tensor{\delta}{_\rho^\lambda}
\end{align}
so we see that $\tensor{\Lambda}{_\nu^\mu}$ is the inverse of $\tensor{\Lambda}{^\mu_\nu}$.


\section{Lie group theory}
\subsection{Invariance, symmetry, and covariance}
We call a quantity \textbf{invariant} if it does not change under particular transformations. E.g. if we transform $A,B,C,... \rightarrow A',B',C',...$ and we have
\begin{equation}
F(A',B',C',...) = F(A,B,C,...)
\end{equation}
then we say $F$ is invariant under this transformation. \textbf{Symmetry} is defined as invariance under a transformation (or class of transformations). An equation is covariant if it takes the same form when objects in it are transformed. \textit{All physical laws must be covariant under Lorentz transformations.} 

Group theory describes the properties of particular sets of transformations: the invariances under such groups allows us to mathematically describe symmetry. For example, the set of rotations about the origin of a square by $n\pi/2$ form a \textbf{discrete group}, and leave the set of points which constitute the square invariant under the transformation. The set of rotations about the origin of a circle form a \textbf{continuous group}. We can use group theory to work with \textit{all} kinds of symmetries: symmetries which operate on vectors, equations, ...

\subsection{Groups}
\begin{defn}[Group axioms]
A group $(G, \circ)$ is a set $G$, together with a binary operation $\circ$ defined on $G$, that satisfies the following axioms
\begin{itemize}
\item Closure: For all $g_1, g_2 \in G$, $g_1 \circ g_2 \in G$
\item Identity element: There exists an identity element $e \in G$ such that for all $g \in G$, $g \circ e = g = e \circ g$
\item Inverse element: For each $g \in G$, there exists an inverse element $g^{-1} \in G$ such that $g \circ g^{-1} = e = g^{-1}g$.
\item Associativity: For all $g_1, g_2, g_3 \in G$, $g_1 \circ (g_2 \circ g_3) = (g_1 \circ g_2) \circ g_3$
\end{itemize}
\end{defn}

The set of all transformations that leave a given object invariant is called a \textbf{symmetry group}. For Minkowski spacetime, the object that is left invariant is the Minkowski metric, and the corresponding symmetry group is called the \textbf{Poincar\'{e} group}. Notice that the transformations which constitute a group are defined entirely independently from the object on which the transformations act.

\subsubsection{Rotations in two dimensions and $SO(2)$}
Consider the 2D rotation matrix 
\begin{equation}
R_\theta = \begin{pmatrix}
\cos(\theta)& -\sin(\theta)\\
\sin(\theta)& \cos(\theta)
\end{pmatrix} \label{eq:2d-rotation-matrix}
\end{equation}
and the two reflection matrices
\begin{equation}
P_x = \begin{pmatrix}
-1& 0\\
0& 1
\end{pmatrix} \qquad 
P_y = \begin{pmatrix}
1& 0\\
0& -1
\end{pmatrix}.
\end{equation}
These matrices satisfy the group axioms. We can uncover this group from a symmetry perspective. The above transformations leave the length of a vector unchanged, i.e.
\begin{equation}
a.a = a'.a'.
\end{equation}
Letting the transformation be represented by $a' = Oa$, it follows that all members of the group must satisfy
\begin{equation}
O^T O = I.
\end{equation}
This condition defines the group $O(2)$, which is the group of all \textbf{orthogonal} 2$\times$2 matrices. It follows that $\det(O)=\pm 1$ -- i.e. the transformations are area-preserving. The subgroup with $\det(O)=1$ is called $SO(2)$, which corresponds to rigid rotations preserving the orientation of the system -- ``S'' denoting \textbf{special}. 

\subsubsection{Rotations with unit complex numbers and $U(1)$}
A unit complex number is a complex number $z$ which satisfies $|z|^2=z^*z=1$. The group $U(1)$ is the set of unit complex numbers, together with ordinary complex number multiplication. The $U$ stands for `\textbf{unitary}`, which generally stands for the condition 
\begin{equation}
U^\dagger U=1,
\end{equation} 
where $U^\dagger = (U^{T})^*$ is the \textbf{Hermitian conjugate} of $U$. For scalars, the Hermitian conjugate is equivalent to the complex conjugate. Note that a unit complex number can also be denoted as 
\begin{equation}
R_\theta = e^{i\theta} = \cos(\theta) + i \sin(\theta)
\end{equation}
which makes the interpretation of $U(1)$ as rotations on the unit complex numbers evident.

We can connect this description of rotations ($U(1)$) to the previous ($SO(2)$) by defining 
\begin{equation}
1 = \begin{pmatrix}
1 & 0\\
0 & 1
\end{pmatrix}\qquad,\qquad
i = \begin{pmatrix}
0 & -1\\
1 & 0
\end{pmatrix}. \label{eq:map-complex-rot-to-2d-vectors}
\end{equation}
For an arbitrary unit complex number $z = a + ib$, let
\begin{equation}
f(z) = a \begin{pmatrix}
1 & 0\\
0 & 1
\end{pmatrix} + b \begin{pmatrix}
0 & -1\\
1 & 0
\end{pmatrix} = \begin{pmatrix}
a & -b\\
b & a
\end{pmatrix}. \label{eq:isomorphism-so2-u1}
\end{equation}
Since $z = R_\theta = \cos(\theta) + i \sin(\theta)$, we can plug in the real and imaginary components of $z$ into Eq.\eqref{eq:isomorphism-so2-u1} to arrive at Eq.\eqref{eq:2d-rotation-matrix}. We then have $z' = R_\theta z$, to perform rotations. There therefore exists an \textbf{isomorphism} between $SO(2)$ and $U(1)$:
\begin{defn}[Group isomorphism]
Given two groups $(G, *)$, $(H, \astrosun)$, a group isomorphism is a bijective function $f: G \rightarrow H$ such that
\begin{equation}
f(u * v) = f(u) \astrosun f(v) \ \forall\ u, v \in G.
\end{equation}
which is written as
\begin{equation}
(G, *) \cong (H, \astrosun).
\end{equation}
\end{defn}
\noindent $f(z)$ in Eq.\eqref{eq:isomorphism-so2-u1} is therefore a group isomorphism between $U(1)$ and $SO(2)$,
\begin{equation}
SO(2) \cong U(1). \label{eq:so2-is-isomorphic-u1}
\end{equation}
This realization has an analogue in three dimensions, which will reveal something fundamental about nature.

\subsubsection{Rotations in three dimensions and $SO(3)$}
As with $SO(2)$, the defining conditions of $SO(3)$ are
\begin{align}
R^TR &= I \label{eq:def-so3-norm-preserving} \\
\det(R) &= 1. \label{eq:def-so3-parity-preserving}
\end{align}
Matrices satisfying these two conditions represent rigid rotations of 3-dimensional vectors. These matrices can be described by the following three ``basis rotations''
\begin{align}
R_x &= \begin{pmatrix}
1 & 0 & 0 \\
0 & \cos(\theta) & -\sin(\theta) \\
0 & \sin(\theta) & \cos(\theta) \\
\end{pmatrix} \qquad 
R_y = \begin{pmatrix}
\cos(\theta) & 0 & \sin(\theta) \\
0 & 1 & 0 \\
-\sin(\theta) & 0 & \cos(\theta) \\
\end{pmatrix} \nonumber \\
R_z &= \begin{pmatrix}
\cos(\theta) & -\sin(\theta) & 0 \\
\sin(\theta) & \cos(\theta) & 0 \\
0 & 0 & 1
\end{pmatrix}.
\end{align}
So, to rotate a vector $v$ around the $z$-axis by $\theta$, we would compute $R_z(\theta) v$. The set of (orientation-preserving) rotation matrices acting on 3-dimensional vectors is called $SO(3)$.

\subsubsection{Quaternions and $SU(2)$}
To get a second description of rotations in three dimensions, we must generalize complex numbers in higher dimensions. Astonishingly, it turns out that there are no 3-dimensional complex numbers. Instead, we can find 4-dimensional complex numbers called quaternions, which will turn out to be able to describe rotations in 3-dimensions. The fact that quaternions are 4-dimensional will reveal something deep about the universe. We could have anticipated this result, because we will be using unit quaternions, which have 3 degrees of freedom.

To construct quaternions, we introduce three complex units satisfying the relations
\begin{align}
\mathbf{i}^2 = \mathbf{j}^2 = \mathbf{k}^2 - -1 \\
\mathbf{ijk} = -1 \\
q = a \mathbf{1} + b\mathbf{i} + c \mathbf{j} + d \mathbf{k}. \label{eq:quaternion-ijk}
\end{align}
All other relations can be computed from the above. For example, the relation $\mathbf{ij}=\mathbf{k}$ can be derived by multiplying both sides of Eq.\eqref{eq:quaternion-ijk} by $\mathbf{k}$. Notice that it follows that the \textbf{basic quaternions} \textbf{anticommute} with each other, see Fig.~\ref{fig:quaternion-multiplication}.

\begin{figure}
\begin{center}
\includegraphics[width=0.2\columnwidth]{figures/quaternion-multiplication.jpg}  
\end{center}
\caption{Quaternion multiplication table, read as row $\times$ column = value. E.g. $\mathbf{ji}=-\mathbf{k}$. In general, the basic quaternions anti-commute.}
\label{fig:quaternion-multiplication}
\end{figure}


The set of unit quaternions satisfy
\begin{align}
q^\dagger q = 1 \\
\implies a^2 + b^2 + c^2 + d^2 = 1.
\end{align}
As the unit complex numbers formed a group under complex number multiplication, the unit quaternions form a group under quaternion multiplication. There are several possible ways of representing the basic quaternions with 2D matrices, but one way is as follows:
\begin{align}
\mathbf{1}&=\begin{pmatrix}
1&0\\
0&1
\end{pmatrix}\qquad,\qquad
\mathbf{i}=\begin{pmatrix}
0&1\\
-1&0
\end{pmatrix} \nonumber \\
\mathbf{j}&=\begin{pmatrix}
0&i\\
i&0
\end{pmatrix}\qquad,\qquad
\mathbf{k}=\begin{pmatrix}
i&0\\
0&-i
\end{pmatrix}. \label{eq:matrix-repn-quaternion}
\end{align}
With these matrices, a generic quaternion $q=a\mathbf{1}+b\mathbf{i}+c\mathbf{j}+d\mathbf{k}$ can be written in a matrix representation as
\begin{equation}
f(q) = \begin{pmatrix}
a+di & b + ci\\
-b + ci & a-di
\end{pmatrix}. \label{eq:quaternion-matrix-repn}
\end{equation}
We also observe that $\det(f(q))=1$, and so we conclude that the unit quaternions are given by the set of matrices with the above form and unit determinant. The unit quaternions, written as 2$\times$2 matrices $U$ therefore fulfil the conditions
\begin{equation}
U^\dagger U=1 \qquad \text{and}\ \det(U)=1.
\end{equation}
This defines the symmetry group $SU(2)$. 

The map between $SU(2)$ and $SO(3)$ is not as simple as the one we saw between $U(1)$ and $SO(2)$. The mapping of a complex number onto a 2-dimensional vector is easy because a complex number has two degrees of freedom: $v=x+\mathbf{i}y$. But the mapping of a quaternion onto 3-dimensional vector is not so straightforward because a quaternion has four degrees of freedom. We will make the mapping of a 3-dimensional vector $(x,y,z)^T$ onto a quaternion $v$ as
\begin{equation}
v \equiv x \mathbf{i} + y \mathbf{j} + z \mathbf{k}.
\end{equation}
Using Eq.\eqref{eq:matrix-repn-quaternion}, we see that $\det(v)=x^2+y^2+z^2$. In order to perform transformations which preserve the length of the vector $(x,y,z)$, we must use transformations which preserve determinants. Therefore, the restriction to \textit{unit} quaternions means that we must restrict to matrices with \textit{unit} determinants\footnote{Since $\det(BA)=\det(B)\det(A)$}. Naively, a first guess would be that simply multiplying a vector $v$ by a unit quaternion $u$ induces a rotation on $v$, but this is not the case because the product of $u$ and $v$ may not belong to $\mathbb{R}\mathbf{i}+\mathbb{R}\mathbf{j}+\mathbb{R}\mathbf{k}$. It turns out that the following transformation can describe rotations in 3-dimensions
\begin{equation}
v'=qvq^{-1}. \label{eq:su2-binary-multiplication}
\end{equation}

Let $t$ be a quaternion defining a rotation through $\phi$, where
\begin{align}
t &= \cos(\frac{\phi}{2}) + \sin(\frac{\phi}{2})u \label{eq:quaternion-3d-rot} \\
u &= u_x \mathbf{i} + u_y \mathbf{j} + u_z \mathbf{k} \\
u^\dagger u &= 1 \implies t^\dagger t = 1.
\end{align}
As an example, suppose we wish to rotate the vector $\vec{v}=(1,0,0)^T$ around the $z$-axis by $\phi$. Then using Eq.\eqref{eq:matrix-repn-quaternion}
\begin{equation}
\vec{v}=(1,0,0)^T \rightarrow v = 1\mathbf{i} + 0 \mathbf{j} + 0 \mathbf{k} = \begin{pmatrix}
0 & 1\\
-1 & 0
\end{pmatrix}.
\end{equation}
From Eq.\eqref{eq:quaternion-3d-rot}, defining $\theta = \phi/2$
\begin{equation}
R_z(\theta)=\cos(\theta) \mathbf{1} + \sin(\theta)\mathbf{k} = \begin{pmatrix}
\cos(\theta) + i \sin(\theta) & 0 \\
0 & \cos(\theta) - i \sin(\theta)
\end{pmatrix}.
\end{equation}
From Eq.\eqref{eq:su2-binary-multiplication}, the rotated vector $v'$ is
\begin{equation}
v' = R_z(\theta) v R_z(\theta)^{-1} = \begin{pmatrix}
0 & \cos(\phi) + i \sin(\phi) \\
-\cos(\phi) + i \sin(\phi) & 0
\end{pmatrix}.
\end{equation}
Using the general quaternion matrix representation Eq.\eqref{eq:quaternion-matrix-repn}, we can equate
\begin{equation}
v'_x = \cos(\phi), \qquad v'_y = \sin(\phi), \qquad v'_z = 0
\end{equation}
as expected.

Inspection of Eq.\eqref{eq:quaternion-3d-rot} reveals that the mapping of unit quaternions onto 3-dimensional rotations is not one-to-one. For example, a rotation by $\phi=\pi$ is equivalent to a rotation by $\phi = 2\pi + \pi = 3\pi$. But,
\begin{align}
t_{\phi=\pi} = \sin(\frac{\pi}{2}) u = u \\
t_{\phi=3\pi} = \sin(\frac{3\pi}{2}) u = -u.
\end{align}
Hence, we call $SU(2)$ a \textbf{double-cover} of $SO(3)$, because every element of $SO(3)$ has two corresponding elements in $SU(2)$ [\textbf{TODO: I think}?]. It is therefore always possible to go unambiguously from $SU(2)$ to $SO(3)$, but not vice versa. 

We will see later that groups which cover other groups are fundamental for quantum spin. Note that the above had one quaternion parameter too many, which may be interpreted as a hint towards relativity: a more natural identification may have been $v=t\mathbf{1}+x\mathbf{i}+y\mathbf{j}+z\mathbf{k}$. Rotations in 4-dimensions require 6 degrees of freedom\footnote{Using ordinary 4$\times$4 matrices, with the constraints $O^TO=1$ and $\det(O)=1$ reduce the 16 components of an arbitrary 4$\times$4 matrix to 6 independent components}. However, there is no 7-dimensional generalisation of complex numbers. But two unit quaternions do have 6 degrees of freedom: we will see later how there is a close connection between two copies of $SU(2)$ and rotations in four dimensions.

\section{Lie algebras}
\subsection{Intuition behind generators}
Consider an element of a continuous group which is arbitrarily close to the identity
\begin{equation}
g(\epsilon) = I + \epsilon X
\end{equation}
where $\epsilon$ is small, and $I$ is the identity (think about 1D rotations for concreteness). We let $X$ remain abstract for the moment. We wish to apply this transformation $N$ times to achieve a finite transformation by a total amount $\theta$, $h(\theta)$. As a result, we may write:
\begin{equation}
h(\theta) = (I + \frac{\theta}{N} X)^N.
\end{equation}
We then take the limit of $N \rightarrow \infty$, which is just the exponential function
\begin{equation}
h(\theta) = \lim_{N \rightarrow \infty} (I + \frac{\theta}{N})^N = e^{\theta X}.
\end{equation}
In this sense, the object $X$ generates the finite transformation $h$, which is why we call $X$ a \textbf{generator}.

We can then differentiate $h(\theta)$ to obtain the generator:
\begin{equation}
X=\left.\deriv{h(\theta)}{\theta}\right|_{\theta=0}. \label{eq:explicit-generator-from-finite-transform}
\end{equation}
If we consider a continuous group of transformations that are given by matrices, we can also make a Taylor expansion of an element of the group about the identity 
\begin{equation}
h(\theta) = \sum_n\frac{1}{n!}\left.\derivn{n}{h}{\theta}\right|_{\theta=0}\theta^n
\end{equation}
which shows how generators generate transformations.

\subsection{An intuitive definition for matrix Lie groups}
For matrix Lie groups, the corresponding Lie algebra can be defined as the collection of objects that give an element of the group when exponentiated. 
\begin{defn}[Lie algebra for matrix Lie groups, non-rigorous]
For a matrix Lie group $G$ (given by $n \times n$ matrices), the Lie algebra $\mathfrak{g}$ of $G$ is given by those $n \times n$ matrices $X$ such that
\begin{equation}
e^{tX}\in G \label{eq:def-generator-lie-matrix-group}
\end{equation}
for $t \in \mathbb{R}$, together with an operation called the Lie bracket, that defines how to combine elements of the Lie algebra
\begin{equation}
[\cdot, \cdot]: \mathfrak{g} \times \mathfrak{g} \rightarrow \mathfrak{g}.
\end{equation}
A Lie algebra is \textbf{closed} under the Lie bracket. 
\end{defn}
Note that, in general $X \circ Y \notin \mathfrak{g}$. 
\begin{thm}
Consider a matrix Lie group $G$ and corresponding Lie algebra $\mathfrak{g}$. If $X, Y \in \mathfrak{g}$ and $g, h \in G$, then
\begin{equation}
g \circ h = e^X \circ e^Y = \underbrace{e^{X + Y + \frac{1}{2}[X,Y]+\frac{1}{12}[X,[X,Y]]-\frac{1}{12}[Y,[X,Y]]+...}}_{\in G} \label{eq:BCH-group-elements-Lie-elements}
\end{equation}
where the right hand side is the Baker-Campbell-Hausdorff formula\footnote{This holds more generally, not only for matrix Lie groups. See also Defn. \ref{defn:Lie-algebra}} and $[X,Y]$ for matrix Lie groups is the \textbf{commutator} of $X$ and $Y$:
\begin{equation}
[X,Y] = XY - YX
\end{equation}
and the commutator corresponds to the Lie bracket.  Eq.\eqref{eq:BCH-group-elements-Lie-elements} connects combinations of elements of the group $G$ to combinations of elements of the Lie algebra $\mathfrak{g}$.
\end{thm}

\subsection{Generators and Lie algebra of $SO(3)$}
Using the norm-preserving condition of $SO(3)$, Eq.~\eqref{eq:def-so3-norm-preserving}, along with Eq.\eqref{eq:def-generator-lie-matrix-group} $O = e^{\theta J}$, yields
\begin{equation}
O^TO = e^{\theta J^T} e^{\theta J} = 1 \implies J^T + J = 0,
\end{equation}
The parity-preserving condition in Eq.\eqref{eq:def-so3-parity-preserving} also yields\footnote{Because $\det(e^A)=e^{\tr(A)}$}
\begin{equation}
\det(e^{\theta J}) = e^{\theta \tr(J)} = 1 \implies \tr(J) = 0.
\end{equation}
A set of three \textbf{basis}\footnote{i.e. all other generators are linear combinations of the basis generators} generators $J_1, J_2, J_3$ fulfilling both of these conditions can be written conveniently as
\begin{equation}
(J_i)_{jk} = - \epsilon_{ijk},
\end{equation}
where $\epsilon_{ijk}$ is the Levi-Civita symbol
\begin{equation}
\epsilon_{ijk} = \begin{cases} 
1\qquad  &\text{if } (i,j,k)=\{(1,2,3), (2,3,1), (3,1,2)\}\\
0\qquad  &\text{if } i=j\text{ or } j=k\text{ or } k=i\\
-1\qquad &\text{if } (i,j,k)=\{(1,3,2), (2,1,3), (3,2,1)\}\\
\end{cases}.
\end{equation}
The corresponding Lie bracket is 
\begin{equation}
[J_i, J_j] = \epsilon_{ijk} J_k.
\end{equation}
In physics, it is conventional to define the generators of $SO(3)$ with an extra $i$, so that we get Hermitian generators\footnote{i.e. $J^\dagger = J$}, to arrive at
\begin{align}
O &= e^{i \phi J} \\
\implies (J_i)_{jk} &= -i \epsilon_{ijk} \\
[J_i, J_k] &= i \epsilon_{ijk} J_k.
\end{align}
We call the Lie bracket relation of the basis generators \textbf{the} Lie algebra of a given group, because everything that is important about a Lie algebra is encoded in the Lie bracket relation of the basis generators.

An alternative way to derive the basis generators is to begin with the finite transformation matrices and apply Eq.\eqref{eq:explicit-generator-from-finite-transform}. However, the above method is more general, whose steps were: 
\begin{enumerate}[noitemsep]
\item Begin with the definition of the group;
\item Use those constraints to derive the basis generators; 
\item Then derive the an explicit form for finite transformations.
\end{enumerate}

\subsection{Formal definition of a Lie algebra}

\begin{defn}[Lie algebra]
A Lie algebra is a vector space $\mathfrak{g}$ over some field $F$ together with a binary operation $[\cdot, \cdot]: \mathfrak{g} \times \mathfrak{g} \rightarrow \mathfrak{g}$ called the Lie bracket satisfying the following axioms: \label{defn:Lie-algebra}
\begin{enumerate}
\item Bilinearity:
\begin{align}
[aX + bY, Z] &= a[X,Z] + b[Y,Z] \\
[Z, aX + bY] &= a[Z,X] + b[Z,Y]
\end{align}
for all scalars $a,b \in F$ and all elements $X,Y,Z \in \mathfrak{g}$.
\item Anticommutativity:
\begin{align}
[X,Y] = -[Y,X] 
\end{align}
for all $X \in \mathfrak{g}$.
\item The Jacobi identity
\begin{equation}
[X,[Y,Z]] + [Z,[X,Y]] + [Y,[Z,X]] = 0
\end{equation}
for all elements $X,Y \in \mathfrak{g}$.
\end{enumerate}
\end{defn}

\newpage
\bibliography{physics-from-symmetry.bib} 

\end{document}